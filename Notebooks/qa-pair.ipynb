{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-Answer pair for evaluation using GPT-4o mini, Ragas and llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv, os, csv\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "Model = os.environ[\"Model\"]\n",
    "\n",
    "# load the document\n",
    "llm = OpenAI(model = \"gpt-3.5-turbo\")\n",
    "documents = SimpleDirectoryReader(input_files=[\"../data/Pmg_lds.md\"]).load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceSplitter(chunk_size=1024, chunk_overlap=50)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "index = VectorStoreIndex(nodes)\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import BaseNode\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate, PromptTemplate\n",
    "from typing import Tuple, List\n",
    "import re\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "# llm = OpenAI(model = \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define the generate answers function to generate answers based on the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_PROMPT = PromptTemplate(\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_answers_for_questions(\n",
    "    questions: List[str], context: str, llm: OpenAI\n",
    ") -> str:\n",
    "    \"\"\"Generate answers for questions given context.\"\"\"\n",
    "    answers = []\n",
    "    for question in questions:\n",
    "        fmt_qa_prompt = QA_PROMPT.format(\n",
    "            context_str=context, query_str=question\n",
    "        )\n",
    "        response_obj = llm.complete(fmt_qa_prompt)\n",
    "        answers.append(str(response_obj))\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### generate qa pairs over an entire list of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_GEN_USER_TMPL = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"generate the relevant questions. \"\n",
    ")\n",
    "\n",
    "QUESTION_GEN_SYS_TMPL = \"\"\"\\\n",
    "Your task is to generate \\\n",
    "{num_questions_per_chunk} thoughtful and relevant questions. \\\n",
    "Each question should be based on the source materials and focus on the text in the document called preach my gospel used by missionaries from the church of Jesus Christ of Latter Day saints. \\\n",
    "Ensure the questions are diverse and cover different aspects of the document. \\\n",
    "For example: How can I effectively find and teach people? \\\n",
    "\"\"\"\n",
    "\n",
    "question_gen_template = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage(role=MessageRole.SYSTEM, content=QUESTION_GEN_SYS_TMPL),\n",
    "        ChatMessage(role=MessageRole.USER, content=QUESTION_GEN_USER_TMPL),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def generate_qa_pairs(\n",
    "    nodes: List[BaseNode], llm: OpenAI, num_questions_per_chunk: int = 10\n",
    ") -> List[Tuple[str, str]]:\n",
    "    \"\"\"Generate questions.\"\"\"\n",
    "    qa_pairs = []\n",
    "    for idx, node in enumerate(nodes):\n",
    "        print(f\"Node {idx}/{len(nodes)}\")\n",
    "        context_str = node.get_content(metadata_mode=\"all\")\n",
    "        fmt_messages = question_gen_template.format_messages(\n",
    "            num_questions_per_chunk=10,\n",
    "            context_str=context_str,\n",
    "        )\n",
    "        chat_response = llm.chat(fmt_messages)\n",
    "        raw_output = chat_response.message.content\n",
    "        result_list = str(raw_output).strip().split(\"\\n\")\n",
    "        cleaned_questions = [\n",
    "            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip()\n",
    "            for question in result_list\n",
    "        ]\n",
    "        answers = generate_answers_for_questions(\n",
    "            cleaned_questions, context_str, llm\n",
    "        )\n",
    "        cur_qa_pairs = list(zip(cleaned_questions, answers))\n",
    "        qa_pairs.extend(cur_qa_pairs)\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0/3\n",
      "Node 1/3\n",
      "Node 2/3\n"
     ]
    }
   ],
   "source": [
    "qa_pairs = generate_qa_pairs(\n",
    "    nodes[:3],\n",
    "    # nodes,\n",
    "    llm,\n",
    "    num_questions_per_chunk=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>How does the First Presidency message suggest ...</td>\n",
       "      <td>The First Presidency message suggests that mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What is the significance of the reference to M...</td>\n",
       "      <td>The reference to Moses 1:39 in the First Presi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>How does the First Presidency message in Preac...</td>\n",
       "      <td>The First Presidency message in Preach My Gosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>In what ways does the First Presidency message...</td>\n",
       "      <td>The First Presidency message indicates that mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>How can missionaries apply the teachings and e...</td>\n",
       "      <td>Missionaries can apply the teachings and exhor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0                                                  1\n",
       "25  How does the First Presidency message suggest ...  The First Presidency message suggests that mis...\n",
       "26  What is the significance of the reference to M...  The reference to Moses 1:39 in the First Presi...\n",
       "27  How does the First Presidency message in Preac...  The First Presidency message in Preach My Gosp...\n",
       "28  In what ways does the First Presidency message...  The First Presidency message indicates that mi...\n",
       "29  How can missionaries apply the teachings and e...  Missionaries can apply the teachings and exhor..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pairs = pd.DataFrame(qa_pairs)\n",
    "pairs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the \"Preach My Gospel\" guide help mis...</td>\n",
       "      <td>The \"Preach My Gospel\" guide helps missionarie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some key principles outlined in the \"...</td>\n",
       "      <td>Some key principles outlined in the \"Preach My...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does \"Preach My Gospel\" emphasize the impo...</td>\n",
       "      <td>\"Preach My Gospel\" emphasizes the importance o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what ways does the document address the imp...</td>\n",
       "      <td>The document may address the importance of bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does \"Preach My Gospel\" guide missionaries...</td>\n",
       "      <td>\"Preach My Gospel\" guides missionaries in adap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                                                  1\n",
       "0  How does the \"Preach My Gospel\" guide help mis...  The \"Preach My Gospel\" guide helps missionarie...\n",
       "1  What are some key principles outlined in the \"...  Some key principles outlined in the \"Preach My...\n",
       "2  How does \"Preach My Gospel\" emphasize the impo...  \"Preach My Gospel\" emphasizes the importance o...\n",
       "3  In what ways does the document address the imp...  The document may address the importance of bui...\n",
       "4  How does \"Preach My Gospel\" guide missionaries...  \"Preach My Gospel\" guides missionaries in adap..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize the testset generator object with the corresponding generator and critic llms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/promise/projects/RAG_PMG/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m max_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# loop through each document (section) to generate Q-A pairs\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdocument\u001b[49m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m question_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_question:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'document' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize a l;sit to store Q-A pairs\n",
    "qa_pairs = []\n",
    "\n",
    "question_count = 0\n",
    "max_question = 10\n",
    "\n",
    "# loop through each document (section) to generate Q-A pairs\n",
    "for doc in document:\n",
    "    if question_count >= max_question:\n",
    "        break\n",
    "    \n",
    "    while question_count < max_question:\n",
    "        \n",
    "        question = query_engine.query(f\"Generate a question based on the following text: {doc.text}\")\n",
    "        answer = query_engine.query(f\"Provide an answer to the following question: {question}\\nBased on the text: {doc.text}\")\n",
    "        manual_quote = query_engine.query(f\"if the {answer} is a direct quote or is the same text from the document source, then add the source. if not do not include the source text.\")\n",
    "\n",
    "        qa_pairs.append([question, answer, manual_quote])\n",
    "        question_count += 1\n",
    "\n",
    "print(qa_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(qa_pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Q-A pairs to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to csv file path\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"./data/qa_dataset.csv\"\n",
    "\n",
    "#write the Q-A pair to the CSV file path\n",
    "\n",
    "with open(csv_file, mode=\"w\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Question\", \"Answer\", \"Manual Quote\"])\n",
    "    writer.writerows(qa_pairs)\n",
    "    \n",
    "print(f\"Data saved successfully to csv file path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
